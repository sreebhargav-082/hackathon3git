# -*- coding: utf-8 -*-
"""Hackathon Final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YAmS_UiffHezod48EM2sY877QLk3NzMe
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Embedding, SpatialDropout1D, Dropout
from IPython.display import display, Markdown
import ipywidgets as widgets

# Load data
df = pd.read_csv('/content/spamraw[1].csv', encoding='ISO-8859-1')
df = df[['type','text']]
df.rename(columns={'type':'label', 'text':'message'}, inplace=True)

# Preprocessing
msg_df = df.copy()
msg_df['msg_type'] = msg_df['label'].map({'ham':0, 'spam':1})

# Train-test split
x_train, x_test, y_train, y_test = train_test_split(msg_df['message'], msg_df['msg_type'], test_size=0.2, random_state=434)

# Tokenization
max_len = 50
trunc_type = 'post'
padding_type = 'post'
oov_tok = '<OOV>'
vocab_size = 500
tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(x_train)

# Padding sequences
training_sequences = tokenizer.texts_to_sequences(x_train)
training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)

# Model definition
embedding_dim = 16
model = Sequential()
model.add(Embedding(vocab_size, embedding_dim, input_length=max_len))
model.add(SpatialDropout1D(0.2))
model.add(GRU(128, return_sequences=False))
model.add(Dropout(0.2))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

# Training
num_epochs = 5
early_stop = EarlyStopping(monitor='val_loss', patience=2)
history = model.fit(training_padded, y_train, epochs=num_epochs, validation_split=0.1, callbacks=[early_stop], verbose=2)

# Prediction function
def predict_spam(message):
    new_seq = tokenizer.texts_to_sequences([message])
    padded = pad_sequences(new_seq, maxlen=max_len, padding=padding_type, truncating=trunc_type)
    prediction = model.predict(padded)
    if prediction >= 0.5:
        return 'Spam'
    else:
        return 'Ham'

# Create input widget
input_widget = widgets.Text(placeholder='Enter a message (type "quit" to exit)')

# Define function to handle input change
def handle_submit(sender):
    user_input = sender.value
    if user_input.lower() == 'quit':
        print("Exiting...")
        input_widget.close()  # Close the input widget
    else:
        prediction = predict_spam(user_input)
        if prediction == 'Spam':
            display(Markdown(f"**{prediction}**"))
        else:
            display(Markdown(f"*{prediction}*"))
        sender.value = ''  # Clear input field

# Register function to handle input change
input_widget.on_submit(handle_submit)

# Display input widget
display(input_widget)